{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a noteboook used to generate the speaker embeddings with the ResNetSE34L model trained with Angular Prototypical loss for multi-speaker training.\n",
    "\n",
    "Before running this script please DON'T FORGET:\n",
    "- to set the right paths in the cell below.\n",
    "\n",
    "Repositories:\n",
    "- TTS: https://github.com/mozilla/TTS\n",
    "- ResNetSE34L: https://github.com/clovaai/voxceleb_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "import random\n",
    "import librosa\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from TTS.utils.generic_utils import load_config\n",
    "from tqdm import tqdm\n",
    "from TTS.utils.speakers import save_speaker_mapping, load_speaker_mapping\n",
    "\n",
    "# you may need to change this depending on your system\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone voxceleb_trainer \n",
    "!git clone https://github.com/clovaai/voxceleb_trainer\n",
    "os.chdir('voxceleb_trainer')\n",
    "!git checkout de675ca3e3b27d21fb6f734558b47d6f4c81ac1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install voxceleb_trainer Requeriments\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download Voxceleb_trainer Checkpoint\n",
    "!wget http://www.robots.ox.ac.uk/~vgg/data/voxceleb/models/baseline_lite_ap.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "#-*- coding: utf-8 -*-\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy, math, pdb, sys, random\n",
    "import time, os, itertools, shutil, importlib\n",
    "from tuneThreshold import tuneThresholdfromScore\n",
    "from DatasetLoader import loadWAV\n",
    "from loss.ge2e import GE2ELoss\n",
    "from loss.angleproto import AngleProtoLoss\n",
    "from loss.cosface import AMSoftmax\n",
    "from loss.arcface import AAMSoftmax\n",
    "from loss.softmax import SoftmaxLoss\n",
    "from loss.protoloss import ProtoLoss\n",
    "from loss.pairwise import PairwiseLoss\n",
    "\n",
    "class SpeakerNet(nn.Module):\n",
    "\n",
    "    def __init__(self, max_frames, lr = 0.0001, margin = 1, scale = 1, hard_rank = 0, hard_prob = 0, model=\"alexnet50\", nOut = 512, nSpeakers = 1000, optimizer = 'adam', encoder_type = 'SAP', normalize = True, trainfunc='contrastive', **kwargs):\n",
    "        super(SpeakerNet, self).__init__();\n",
    "\n",
    "        argsdict = {'nOut': nOut, 'encoder_type':encoder_type}\n",
    "\n",
    "        SpeakerNetModel = importlib.import_module('models.'+model).__getattribute__(model)\n",
    "        self.__S__ = SpeakerNetModel(**argsdict).cuda();\n",
    "\n",
    "        if trainfunc == 'angleproto':\n",
    "            self.__L__ = AngleProtoLoss().cuda()\n",
    "            self.__train_normalize__    = True\n",
    "            self.__test_normalize__     = True\n",
    "        elif trainfunc == 'ge2e':\n",
    "            self.__L__ = GE2ELoss().cuda()\n",
    "            self.__train_normalize__    = True\n",
    "            self.__test_normalize__     = True\n",
    "        elif trainfunc == 'amsoftmax':\n",
    "            self.__L__ = AMSoftmax(in_feats=nOut, n_classes=nSpeakers, m=margin, s=scale).cuda()\n",
    "            self.__train_normalize__    = False\n",
    "            self.__test_normalize__     = True\n",
    "        elif trainfunc == 'aamsoftmax':\n",
    "            self.__L__ = AAMSoftmax(in_feats=nOut, n_classes=nSpeakers, m=margin, s=scale).cuda()\n",
    "            self.__train_normalize__    = False\n",
    "            self.__test_normalize__     = True\n",
    "        elif trainfunc == 'softmax':\n",
    "            self.__L__ = SoftmaxLoss(in_feats=nOut, n_classes=nSpeakers).cuda()\n",
    "            self.__train_normalize__    = False\n",
    "            self.__test_normalize__     = True\n",
    "        elif trainfunc == 'proto':\n",
    "            self.__L__ = ProtoLoss().cuda()\n",
    "            self.__train_normalize__    = False\n",
    "            self.__test_normalize__     = False\n",
    "        elif trainfunc == 'triplet':\n",
    "            self.__L__ = PairwiseLoss(loss_func='triplet', hard_rank=hard_rank, hard_prob=hard_prob, margin=margin).cuda()\n",
    "            self.__train_normalize__    = True\n",
    "            self.__test_normalize__     = True\n",
    "        elif trainfunc == 'contrastive':\n",
    "            self.__L__ = PairwiseLoss(loss_func='contrastive', hard_rank=hard_rank, hard_prob=hard_prob, margin=margin).cuda()\n",
    "            self.__train_normalize__    = True\n",
    "            self.__test_normalize__     = True\n",
    "        else:\n",
    "            raise ValueError('Undefined loss.')\n",
    "\n",
    "        if optimizer == 'adam':\n",
    "            self.__optimizer__ = torch.optim.Adam(self.parameters(), lr = lr);\n",
    "        elif optimizer == 'sgd':\n",
    "            self.__optimizer__ = torch.optim.SGD(self.parameters(), lr = lr, momentum = 0.9, weight_decay=5e-5);\n",
    "        else:\n",
    "            raise ValueError('Undefined optimizer.')\n",
    "        \n",
    "        self.__max_frames__ = max_frames\n",
    "\n",
    "    ## ===== ===== ===== ===== ===== ===== ===== =====\n",
    "    ## extract Embedding from file\n",
    "    ## ===== ===== ===== ===== ===== ===== ===== =====\n",
    "    \n",
    "    def ExtractEmbedding(self, file_path, num_eval=10):\n",
    "\n",
    "        inp1 = loadWAV(file_path, self.__max_frames__, evalmode=True, num_eval=num_eval).cuda()\n",
    "        emb = self.__S__.forward(inp1).detach().cpu()\n",
    "        # apply L2 norm on Embedding\n",
    "        if self.__test_normalize__:\n",
    "            emb = F.normalize(emb, p=2, dim=1)# apply L2 norm\n",
    "\n",
    "        return emb.cpu().numpy()\n",
    "\n",
    "    ## ===== ===== ===== ===== ===== ===== ===== =====\n",
    "    ## Load parameters\n",
    "    ## ===== ===== ===== ===== ===== ===== ===== =====\n",
    "\n",
    "    def loadParameters(self, path):\n",
    "\n",
    "        self_state = self.state_dict();\n",
    "        loaded_state = torch.load(path);\n",
    "        for name, param in loaded_state.items():\n",
    "            origname = name;\n",
    "            if name not in self_state:\n",
    "                name = name.replace(\"module.\", \"\");\n",
    "\n",
    "                if name not in self_state:\n",
    "                    print(\"%s is not in the model.\"%origname);\n",
    "                    continue;\n",
    "\n",
    "            if self_state[name].size() != loaded_state[origname].size():\n",
    "                print(\"Wrong parameter length: %s, model: %s, loaded: %s\"%(origname, self_state[name].size(), loaded_state[origname].size()));\n",
    "                continue;\n",
    "\n",
    "            self_state[name].copy_(param);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parms = {'max_frames':300,'batch_size':200,'max_seg_per_spk':100,\n",
    "         'nDataLoaderThread':5,'test_interval':10,'max_epoch':500,\n",
    "         'trainfunc':\"angleproto\",'optimizer':\"adam\",'lr':0.001,\"lr_decay\":0.95,\n",
    "         \"hard_prob\":0.5,\"hard_rank\":10,'margin':1,'scale':15, \n",
    "         'nSpeakers':6200,'save_path':\"data/test\",\n",
    "         'train_list':\"\",'test_list':\"\",'train_path':\"voxceleb2\",\n",
    "         'test_path':\"voxceleb1\",'eval':True,\n",
    "         'model':\"ResNetSE34L\",'encoder':\"SAP\",'nOut':512, 'initial_model':\"./baseline_lite_ap.model\"\n",
    "        }\n",
    "\n",
    "SpNet = SpeakerNet(**parms)\n",
    "SpNet.loadParameters(parms['initial_model']);\n",
    "print(\"Model %s loaded!\"%parms['initial_model']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set constants\n",
    "ROOT_PATH = '../../../'\n",
    "CONFIG_PATH = os.path.join(ROOT_PATH, 'config-pt-ideal.json')\n",
    "CONFIG = load_config(CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess dataset\n",
    "meta_data = []\n",
    "datasets=CONFIG.datasets\n",
    "for dataset in datasets:\n",
    "    preprocessor = importlib.import_module('TTS.datasets.preprocess')\n",
    "    preprocessor = getattr(preprocessor,  dataset['name'].lower())\n",
    "    meta_data += preprocessor(dataset['path'],dataset['meta_file_train'])\n",
    "      \n",
    "\n",
    "#random.shuffle(meta_data)\n",
    "meta_data= meta_data\n",
    "\n",
    "meta_data = meta_data\n",
    "embeddings_dict = {}\n",
    "len_meta_data= len(meta_data)\n",
    "for i in tqdm(range(len_meta_data)):\n",
    "    _, wave_file_path, speaker_id = meta_data[i]\n",
    "    wav_file_name = os.path.basename(wave_file_path)\n",
    "    # Extract Embedding\n",
    "    file_embeddings = SpNet.ExtractEmbedding(wave_file_path)\n",
    "    embeddings_dict[wav_file_name] = [np.mean(np.array(file_embeddings), axis=0).reshape(-1).tolist(), speaker_id]\n",
    "    del file_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and export speakers.json  and aplly a L2_norm in embedding\n",
    "speaker_mapping = {sample: {'name': embeddings_dict[sample][1], 'embedding':embeddings_dict[sample][0]} for i, sample in enumerate(embeddings_dict.keys())}\n",
    "save_speaker_mapping(ROOT_PATH, speaker_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test load integrity\n",
    "speaker_mapping_load = load_speaker_mapping(ROOT_PATH)\n",
    "assert speaker_mapping == speaker_mapping_load\n",
    "print(\"The file speakers.json has been exported to \",ROOT_PATH, ' with ', len(embeddings_dict.keys()), ' speakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
