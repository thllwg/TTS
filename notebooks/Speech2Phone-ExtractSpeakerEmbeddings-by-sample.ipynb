{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a noteboook used to generate the speaker embeddings with the Speech2Phone model for multi-speaker training.\n",
    "\n",
    "Before running this script please DON'T FORGET: \n",
    "- to set file paths.\n",
    "- to download related model files from TTS.\n",
    "- download or clone related repos, linked below.\n",
    "- setup the repositories. ```python setup.py install```\n",
    "- to checkout right commit versions (given next to the model) of TTS.\n",
    "- to set the right paths in the cell below.\n",
    "\n",
    "Repositories:\n",
    "- TTS: https://github.com/mozilla/TTS\n",
    "- Speech2Phone: https://github.com/Edresson/Speech2Phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import importlib\n",
    "import random\n",
    "import librosa\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from TTS.utils.generic_utils import load_config\n",
    "from tqdm import tqdm\n",
    "from TTS.utils.speakers import save_speaker_mapping, load_speaker_mapping\n",
    "\n",
    "# you may need to change this depending on your system\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set constants\n",
    "ROOT_PATH = '../../'\n",
    "SAVE_PATH =  '../../speech2phone-brspeech/'\n",
    "CONFIG_PATH = os.path.join(ROOT_PATH, 'config-pt-ideal.json')\n",
    "CONFIG = load_config(CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Speech2Phone Requeriments\n",
    "!pip install pydub tensorflow==1.14.0 tflearn==0.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download Speech2Phone Checkpoint\n",
    "!wget -O ./saver.zip https://www.dropbox.com/s/b19xt2wu3th9p36/Save-Models-Speaker-Diarization.zip?dl=0\n",
    "!mkdir Speech2Phone\n",
    "!unzip saver.zip\n",
    "!mv  Save-Models/  Speech2Phone/Save-Models/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utils for Speech2Phone Preprocessing\n",
    "from pydub import AudioSegment as audio\n",
    "\n",
    "def detect_leading_silence(sound, silence_threshold=-50.0, chunk_size=10):\n",
    "    '''\n",
    "    sound is a pydub.AudioSegment\n",
    "    silence_threshold in dB\n",
    "    chunk_size in ms\n",
    " \n",
    "    iterate over chunks until you find the first one with sound\n",
    "    '''\n",
    "    trim_ms = 0  # ms\n",
    "    while sound[trim_ms:trim_ms+chunk_size].dBFS < silence_threshold:\n",
    "        #print(trim_ms,len(sound))\n",
    "        if trim_ms > len(sound):\n",
    "            return None\n",
    "        trim_ms += chunk_size\n",
    " \n",
    "    return trim_ms\n",
    "\n",
    "def remove_silence(sound):\n",
    "    start_trim = detect_leading_silence(sound)\n",
    "    if start_trim is None:\n",
    "        return None\n",
    "    end_trim = detect_leading_silence(sound.reverse())\n",
    "    duration = len(sound)\n",
    "    trimmed_sound = sound[start_trim:duration-end_trim]\n",
    "    return trimmed_sound\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/store/ecasanova/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/store/ecasanova/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/store/ecasanova/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/store/ecasanova/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/store/ecasanova/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/store/ecasanova/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/store/ecasanova/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/store/ecasanova/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/store/ecasanova/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/store/ecasanova/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/store/ecasanova/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/store/ecasanova/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /store/ecasanova/anaconda3/lib/python3.7/site-packages/tflearn/helpers/summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "WARNING:tensorflow:From /store/ecasanova/anaconda3/lib/python3.7/site-packages/tflearn/helpers/trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From /store/ecasanova/anaconda3/lib/python3.7/site-packages/tflearn/collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /store/ecasanova/anaconda3/lib/python3.7/site-packages/tflearn/config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /store/ecasanova/anaconda3/lib/python3.7/site-packages/tflearn/config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /store/ecasanova/anaconda3/lib/python3.7/site-packages/tflearn/config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /store/ecasanova/anaconda3/lib/python3.7/site-packages/tflearn/layers/core.py:81: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /store/ecasanova/anaconda3/lib/python3.7/site-packages/tflearn/layers/core.py:239: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:From /store/ecasanova/anaconda3/lib/python3.7/site-packages/tflearn/initializations.py:174: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /store/ecasanova/anaconda3/lib/python3.7/site-packages/tflearn/optimizers.py:238: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /store/ecasanova/anaconda3/lib/python3.7/site-packages/tflearn/summaries.py:46: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /store/ecasanova/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /store/ecasanova/anaconda3/lib/python3.7/site-packages/tflearn/helpers/trainer.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /store/ecasanova/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /store/ecasanova/voice-clonning/TTS/notebooks/Speech2Phone/Save-Models/Model3-Best-40loc.tflearn\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "\n",
    "#Create model for restore\n",
    "encoder = tflearn.input_data(shape=[None, 13,int(216)])\n",
    "encoder = tflearn.dropout(encoder,0.9) #10 % drop - 90% -> 80\n",
    "encoder = tflearn.dropout(encoder,0.2)# 80 % drop\n",
    "encoder = tflearn.fully_connected(encoder, 40,activation='crelu')\n",
    "decoder = tflearn.fully_connected(encoder, int(572), activation='linear')\n",
    "net = tflearn.regression(decoder, optimizer='adam', learning_rate=0.0007,loss='mean_square', metric=None)#categorical_crossentropy\n",
    "model = tflearn.DNN(net, tensorboard_verbose=0,tensorboard_dir='tflearn_logs')\n",
    "\n",
    "model.load('./Speech2Phone/Save-Models/Model3-Best-40loc.tflearn')\n",
    "\n",
    "encoding_model = tflearn.DNN(encoder, session=model.session)# used for extract embedding in encoder layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess dataset\n",
    "meta_data = []\n",
    "datasets=CONFIG.datasets\n",
    "for dataset in datasets:\n",
    "    preprocessor = importlib.import_module('TTS.datasets.preprocess')\n",
    "    preprocessor = getattr(preprocessor,  dataset['name'].lower())\n",
    "    meta_data += preprocessor(dataset['path'],dataset['meta_file_train'])\n",
    "      \n",
    "meta_data= list(meta_data)\n",
    "#random.shuffle(meta_data)\n",
    "iis = []\n",
    "meta_data = meta_data\n",
    "embeddings_dict = {}\n",
    "len_meta_data= len(meta_data)\n",
    "for i in tqdm(range(len_meta_data)):\n",
    "    _, wave_file_path, speaker_id = meta_data[i]\n",
    "    wav_file_name = os.path.basename(wave_file_path)\n",
    "    try:\n",
    "        sound = audio.from_wav(wave_file_path)\n",
    "    except:\n",
    "        print(\"erro ler arquivo\")\n",
    "        continue\n",
    "    wave = remove_silence(sound)\n",
    "    if wave is None:\n",
    "        print(\"erro remove silence\")\n",
    "        continue\n",
    "    \n",
    "    file_embeddings = None\n",
    "    begin = 0\n",
    "    end = 5\n",
    "    step = 1 \n",
    "    if int(wave.duration_seconds) < 5: # 5 seconds is the Speech2Phone input if is small concate\n",
    "        aux = wave\n",
    "        while int(aux.duration_seconds) <= 5:\n",
    "            aux += wave\n",
    "        wave = aux\n",
    "        del aux\n",
    "        \n",
    "    while (end) <= int(wave.duration_seconds):\n",
    "        try:        \n",
    "            segment = wave[begin*1000:end*1000]\n",
    "            segment.export('../aux' + '.wav', 'wav')# its necessary because pydub and librosa load wave in diferent form \n",
    "            y, sr = librosa.load('../aux.wav',sr=22050)#sample rate = 22050 \n",
    "\n",
    "            if file_embeddings is None:\n",
    "                file_embeddings =[np.array(encoding_model.predict([librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)])[0])]\n",
    "            else:\n",
    "                file_embeddings.append(np.array(encoding_model.predict([librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)])[0]))   \n",
    "            os.system('rm ../aux.wav')\n",
    "            begin = begin + step\n",
    "            end = end + step\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('parte do arquivo deu erro', len(file_embeddings))\n",
    "            begin = begin + step\n",
    "            end = end + step\n",
    "        \n",
    "    iis.append(i)\n",
    "    embeddings_dict[wav_file_name] = [np.mean(np.array(file_embeddings), axis=0) if len(file_embeddings) > 1 else np.array(file_embeddings), speaker_id]\n",
    "    del file_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and export speakers.json  and aplly a L2_norm in embedding\n",
    "speaker_mapping = {sample: {'name': embeddings_dict[sample][1], 'embedding':torch.nn.functional.normalize(torch.FloatTensor([embeddings_dict[sample][0].reshape(-1).tolist()]), p=2, dim=1).reshape(-1).tolist()} for i, sample in enumerate(embeddings_dict.keys())}\n",
    "save_speaker_mapping(SAVE_PATH, speaker_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test load integrity\n",
    "speaker_mapping_load = load_speaker_mapping(SAVE_PATH)\n",
    "assert speaker_mapping == speaker_mapping_load\n",
    "print(\"The file speakers.json has been exported to \",ROOT_PATH, ' with ', len(speaker_mapping_load.keys()), ' speakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(meta_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(iis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''speaker_mapping_load = load_speaker_mapping(os.path.join(ROOT_PATH, 'speakers-en-vctk-GE2E-ResNetSE34L.json'))\n",
    "print(len(speaker_mapping_load.keys()))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PT\n",
    "'''speaker_mapping_load = load_speaker_mapping(os.path.join(ROOT_PATH, 'speakers-pt-Speech2Phone-BRSpeech-beta3.json'))\n",
    "print(len(speaker_mapping_load.keys()))'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
